from fastapi import FastAPI, Response
from contextlib import asynccontextmanager
from playwright.async_api import async_playwright, Browser, Page
import uvicorn
import asyncio
import datetime
from typing import Dict, Any, Optional, List
from shop import scrape_all_shops

# ==============================================================================
# 1. CENTRAL DATA STORE (‡∏Å‡∏≠‡∏á‡∏Å‡∏•‡∏≤‡∏á‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
# ==============================================================================
GLOBAL_CACHE: Dict[str, Any] = {
    "gold_bar_data": [],      # ‡πÄ‡∏Å‡πá‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ó‡πà‡∏á
    "jewelry_percent": [],    # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏û‡∏£‡∏£‡∏ì (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ %)
    "shop_data": [],          # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å 5 ‡∏£‡πâ‡∏≤‡∏ô‡∏ó‡∏≠‡∏á
    "last_updated": None,     # ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    "market_status": "Initializing...",
    "source_type": "None"     # ‡πÄ‡∏Å‡πá‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏´‡∏ô‡∏≠‡∏¢‡∏π‡πà (New/Classic/None)
}

playwright_instance = None
browser_instance: Optional[Browser] = None

# ==============================================================================
# 2. HELPER FUNCTIONS
# ==============================================================================
def get_thai_time():
    """‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢ (UTC+7)"""
    tz = datetime.timezone(datetime.timedelta(hours=7))
    return datetime.datetime.now(tz)

def is_market_open():
    """
    ‡πÄ‡∏ä‡πá‡∏Ñ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î Gold Traders
    - ‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå-‡∏®‡∏∏‡∏Å‡∏£‡πå: 09:00 - 17:45
    - ‡πÄ‡∏™‡∏≤‡∏£‡πå: 09:00 - 09:30
    - ‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå: ‡∏õ‡∏¥‡∏î
    """
    now = get_thai_time()
    weekday = now.weekday() # 0=Mon, 6=Sun
    current = now.time()

    # ‡∏ß‡∏±‡∏ô‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå (6): ‡∏õ‡∏¥‡∏î‡∏ï‡∏•‡∏≠‡∏î‡∏ß‡∏±‡∏ô
    if weekday == 6: 
        return False, "Closed (Sunday)"
    
    # ‡∏ß‡∏±‡∏ô‡πÄ‡∏™‡∏≤‡∏£‡πå (5): ‡πÄ‡∏õ‡∏¥‡∏î‡πÅ‡∏Ñ‡πà 09:00 - 09:30
    if weekday == 5:
        if datetime.time(9, 0) <= current <= datetime.time(9, 30):
            return True, "Open (Sat Morning)"
        return False, "Closed (Sat > 09:30)"

    # ‡∏ß‡∏±‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ (0-4): ‡πÄ‡∏õ‡∏¥‡∏î 09:00 - 17:45
    if datetime.time(9, 0) <= current <= datetime.time(17, 45):
        return True, "Open (Weekday)"
        
    return False, "Closed (Outside Hours)"

def is_shop_open():
    """
    ‡πÄ‡∏ä‡πá‡∏Ñ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤ (24/7 ‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏õ‡∏¥‡∏î‡πÄ‡∏™‡∏≤‡∏£‡πå 9:30 - ‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå 00:00)
    - ‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå (0) - ‡∏®‡∏∏‡∏Å‡∏£‡πå (4): ‡πÄ‡∏õ‡∏¥‡∏î 24 ‡∏ä‡∏°.
    - ‡πÄ‡∏™‡∏≤‡∏£‡πå (5): ‡∏õ‡∏¥‡∏î‡∏´‡∏•‡∏±‡∏á 09:30
    - ‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå (6): ‡∏õ‡∏¥‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏ß‡∏±‡∏ô
    """
    now = get_thai_time()
    weekday = now.weekday()
    current_time = now.time()

    # ‡∏ß‡∏±‡∏ô‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå (6): ‡∏õ‡∏¥‡∏î‡∏ï‡∏•‡∏≠‡∏î‡∏ß‡∏±‡∏ô
    if weekday == 6:
        return False, "Closed (Sunday)"

    # ‡∏ß‡∏±‡∏ô‡πÄ‡∏™‡∏≤‡∏£‡πå (5): ‡∏õ‡∏¥‡∏î‡∏´‡∏•‡∏±‡∏á 09:30
    if weekday == 5:
        if current_time >= datetime.time(9, 30):
            return False, "Closed (Saturday > 09:30)"

    # ‡∏ß‡∏±‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÜ (‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå-‡∏®‡∏∏‡∏Å‡∏£‡πå): ‡πÄ‡∏õ‡∏¥‡∏î‡∏ï‡∏•‡∏≠‡∏î
    return True, "Open (24h)"

# ==============================================================================
# 3. SCRAPING LOGIC (‡πÅ‡∏¢‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏ß‡πá‡∏ö)
# ==============================================================================

# --- LOGIC A: ‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà (Clean URL) ---
async def scrape_new_version(page: Page) -> Dict[str, Any]:
    print("   üëâ Trying New Version Logic...")
    await page.goto("https://www.goldtraders.or.th/updatepricelist", timeout=15000)
    await page.wait_for_selector("table tbody tr", timeout=5000) 

    # 1. Gold Bar
    gold_data = []
    rows = await page.locator("table tbody tr").all()
    for row in rows:
        cells = await row.locator("td").all()
        if len(cells) >= 10:
            texts = await asyncio.gather(*[cell.inner_text() for cell in cells])
            gold_data.append({
                "date": texts[0].strip(),
                "time": texts[1].strip(),
                "round": texts[2].strip(),
                "ornament_buy": texts[3].strip(),
                "ornament_sell": texts[4].strip(),
                "bullion_buy": texts[5].strip(),
                "bullion_sell": texts[6].strip(),
                "gold_spot": texts[7].strip(),
                "thb": texts[8].strip(),
                "change": texts[9].replace('\n', '').strip()
            })

    # 2. Jewelry Percent
    jewelry_data = []
    try:
        await page.goto("https://www.goldtraders.or.th/dailyprices", timeout=15000)
        await page.wait_for_selector("td:has-text('96.5%')", timeout=5000)
        rows = await page.locator("table").filter(has_text="96.5%").locator("tbody tr").all()
        for row in rows:
            cells = await row.locator("td").all()
            if len(cells) >= 4:
                texts = await asyncio.gather(*[cell.inner_text() for cell in cells])
                jewelry_data.append({
                    "type": texts[0].strip(),
                    "buy": texts[2].strip(),
                    "sell": texts[3].strip()
                })
    except Exception as e:
        print(f"   ‚ö†Ô∏è New Version Jewelry Error: {e}")

    return {"gold": gold_data, "jewelry": jewelry_data, "source": "New Website"}

# --- LOGIC B: ‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏Å‡πà‡∏≤ (Classic .aspx) ---
async def scrape_classic_version(page: Page) -> Dict[str, Any]:
    print("   üëâ Trying Classic Version Logic (Fallback)...")
    await page.goto("https://www.goldtraders.or.th/UpdatePriceList.aspx", timeout=15000)
    await page.wait_for_selector("#DetailPlace_MainGridView", timeout=5000)

    # 1. Gold Bar
    gold_data = []
    rows = await page.locator("#DetailPlace_MainGridView tr:has(td)").all()
    for row in rows:
        cells = await row.locator("td").all()
        if len(cells) >= 9:
            texts = await asyncio.gather(*[cell.inner_text() for cell in cells])
            raw_dt = texts[0].strip().split()
            d_part = raw_dt[0] if len(raw_dt) > 0 else ""
            t_part = raw_dt[1] if len(raw_dt) > 1 else ""
            
            gold_data.append({
                "date": d_part,
                "time": t_part,
                "round": texts[1].strip(),
                "bullion_buy": texts[2].strip(),
                "bullion_sell": texts[3].strip(),
                "ornament_buy": texts[4].strip(),
                "ornament_sell": texts[5].strip(),
                "gold_spot": texts[6].strip(),
                "thb": texts[7].strip(),
                "change": texts[8].strip()
            })

    # 2. Jewelry Percent
    jewelry_data = []
    try:
        await page.goto("https://www.goldtraders.or.th/DailyPrices.aspx", timeout=15000)
        await page.wait_for_selector("#DetailPlace_MainGridView", timeout=5000)
        rows = await page.locator("#DetailPlace_MainGridView tr:has(td)").all()
        for row in rows:
            cells = await row.locator("td").all()
            if len(cells) >= 4:
                texts = await asyncio.gather(*[cell.inner_text() for cell in cells])
                jewelry_data.append({
                    "type": texts[0].strip(),
                    "buy": texts[2].strip(),
                    "sell": texts[3].strip()
                })
    except Exception as e:
        print(f"   ‚ö†Ô∏è Classic Version Jewelry Error: {e}")

    return {"gold": gold_data, "jewelry": jewelry_data, "source": "Classic Website"}

# ==============================================================================
# 4. ORCHESTRATOR & LIFECYCLE MANAGEMENT
# ==============================================================================

async def start_browser():
    global playwright_instance, browser_instance
    if browser_instance: return 

    # print("üöÄ [System] Waking up... Starting Browser Engine")
    playwright_instance = await async_playwright().start()
    browser_instance = await playwright_instance.chromium.launch(
        headless=True,
        args=[
            '--no-sandbox', 
            '--disable-setuid-sandbox', 
            '--disable-dev-shm-usage',
            '--disable-gpu',
            '--disable-extensions',
            '--no-zygote'
        ]
    )

async def stop_browser():
    global playwright_instance, browser_instance
    if not browser_instance: return 

    print("üí§ [System] Hibernate Mode... Shutting down Browser Engine")
    try:
        if browser_instance:
            await browser_instance.close()
        if playwright_instance:
            await playwright_instance.stop()
    except Exception as e:
        print(f"   ‚ö†Ô∏è Shutdown Warning: {e}")
    finally:
        browser_instance = None
        playwright_instance = None

async def update_all_data(scrape_gold: bool = True, scrape_shops: bool = False):
    global GLOBAL_CACHE
    now_str = get_thai_time().strftime('%H:%M:%S')
    
    # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ Source ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÑ‡∏ß‡πâ (Sticky Session)
    current_source = GLOBAL_CACHE.get("source_type", "None")

    if not browser_instance: 
        print("‚ùå Error: Browser not running!")
        return

    context = await browser_instance.new_context(
        user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )
    
    try:
        page = await context.new_page()
        
        result_data = None
        
        # --- PHASE 1 & 2: Gold Traders (Only if requested) ---
        if scrape_gold:
            # --- PHASE 1: Fast Track ---
            if current_source == "New Website":
                try:
                    result_data = await scrape_new_version(page)
                except Exception:
                    current_source = "None"

            elif current_source == "Classic Website":
                try:
                    result_data = await scrape_classic_version(page)
                except Exception:
                    current_source = "None"

            # --- PHASE 2: Discovery Mode ---
            if current_source == "None" or result_data is None:
                # print(f"üîç [{now_str}] Discovery Mode: Finding active website...")
                try:
                    result_data = await scrape_new_version(page)
                except Exception:
                    try:
                        result_data = await scrape_classic_version(page)
                    except Exception:
                        print("   ‚ùå All sources failed.")

            # --- SAVE DATA ---
            if result_data:
                if result_data["gold"]: GLOBAL_CACHE["gold_bar_data"] = result_data["gold"]
                if result_data["jewelry"]: GLOBAL_CACHE["jewelry_percent"] = result_data["jewelry"]
                GLOBAL_CACHE["source_type"] = result_data["source"]
            else:
                GLOBAL_CACHE["source_type"] = "None"

        # --- PHASE 3: Shop Scraping (Parallel) - Only if requested ---
        if scrape_shops:
            print(f"üè≠ [{now_str}] Scraping 5 Shops...")
            try:
                shop_results = await scrape_all_shops(context)
                GLOBAL_CACHE["shop_data"] = shop_results
            except Exception as e:
                print(f"   ‚ùå Shop Scraping Error: {e}")

        GLOBAL_CACHE["last_updated"] = get_thai_time().strftime("%Y-%m-%d %H:%M:%S")

    except Exception as e:
        print(f"üî• Critical System Error: {e}")
        GLOBAL_CACHE["source_type"] = "None"
    
    finally:
        # üõ°Ô∏è CLEANUP: Always close the context!
        await context.close()

async def run_scheduler():
    tick_counter = 0
    while True:
        is_open, status_msg = is_market_open()
        is_shops_active, shop_status_msg = is_shop_open()
        
        GLOBAL_CACHE["market_status"] = f"{status_msg} | {shop_status_msg}"
        
        # Logic: 
        # 1. Gold Traders: ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏•‡∏≤‡∏î‡πÄ‡∏õ‡∏¥‡∏î + ‡∏ó‡∏∏‡∏Å 2 ‡∏ô‡∏≤‡∏ó‡∏µ (tick % 2 == 0) -> ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢
        # 2. Shops: ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡∏•‡∏≠‡∏î (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏õ‡∏¥‡∏î‡∏™‡∏∏‡∏î‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå) + ‡∏ó‡∏∏‡∏Å 5 ‡∏ô‡∏≤‡∏ó‡∏µ (tick % 5 == 0)
        
        do_scrape_gold = is_open and (tick_counter % 2 == 0)
        do_scrape_shops = is_shops_active and (tick_counter % 5 == 0)

        # Optimization: Hibernate (Auto-Wake / Auto-Sleep)
        if do_scrape_gold or do_scrape_shops:
             # Wake Up
             await start_browser()
             await update_all_data(scrape_gold=do_scrape_gold, scrape_shops=do_scrape_shops)
        else:
             # Hibernate
             await stop_browser()
             if tick_counter % 60 == 0:
                print(f"üí§ Market Closed ({GLOBAL_CACHE['market_status']}) - RAM Saved!")
        
        tick_counter += 1
        await asyncio.sleep(60)

# ==============================================================================
# 5. LIFESPAN & API ENDPOINTS
# ==============================================================================
@asynccontextmanager
async def lifespan(app: FastAPI):
    global playwright_instance, browser_instance
    print("üöÄ Hybrid System Starting (with Hibernate Mode)...")
    
    # 1. ‡∏¢‡πâ‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏Å (Initial Scrape) ‡πÑ‡∏õ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô Background Task
    # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ FastAPI Start Server ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏ó‡∏±‡∏ô‡∏ó‡∏µ (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Error 502 / Health Check Timeout)
    async def initial_startup():
        print("‚è≥ Incoming: Initial Scrape (Background)...")
        await start_browser()
        
        # Force Scrape: ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 1 ‡∏£‡∏≠‡∏ö‡∏ï‡∏≠‡∏ô‡πÄ‡∏õ‡∏¥‡∏î Server ‡πÄ‡∏™‡∏°‡∏≠ (‡πÑ‡∏°‡πà‡∏™‡∏ô‡∏ï‡∏•‡∏≤‡∏î‡πÄ‡∏õ‡∏¥‡∏î/‡∏õ‡∏¥‡∏î)
        # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Cache ‡πÑ‡∏õ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• (‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡∏Ç‡∏∂‡πâ‡∏ô waiting_for_data)
        await update_all_data(scrape_gold=True, scrape_shops=True)
        
        # ‡πÄ‡∏£‡∏¥‡πà‡∏° Scheduler ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å Initial Scrape ‡πÄ‡∏™‡∏£‡πá‡∏à
        asyncio.create_task(run_scheduler())

    asyncio.create_task(initial_startup())
    
    yield
    
    print("üõë System Stopping...")
    await stop_browser()

app = FastAPI(lifespan=lifespan)

@app.get("/")
def read_root(response: Response):
    response.headers["Cache-Control"] = "public, max-age=10, s-maxage=10"
    return {
        "message": "Thai Gold Price API (Hybrid Auto-Switch)",
        "source_used": GLOBAL_CACHE["source_type"],
        "market_status": GLOBAL_CACHE["market_status"],
        "last_updated": GLOBAL_CACHE["last_updated"]
    }

@app.get("/api/latest")
def get_latest(response: Response):
    data = GLOBAL_CACHE["gold_bar_data"]
    if not data:
        return {"status": "waiting_for_data", "market_status": GLOBAL_CACHE["market_status"]}
    
    response.headers["Cache-Control"] = "public, max-age=60, s-maxage=60"
    
    # Logic ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ï‡∏≤‡∏° Source
    latest_item = {}
    if GLOBAL_CACHE["source_type"] == "Classic Website":
        latest_item = data[0]
    else:
        latest_item = data[-1]

    return {
        "status": "success",
        "source": GLOBAL_CACHE["source_type"],
        "data": latest_item,
        "updated_at": GLOBAL_CACHE["last_updated"]
    }

@app.get("/api/gold")
def get_gold_buy_only(response: Response):
    data = GLOBAL_CACHE["gold_bar_data"]
    if not data: return {"status": "waiting_for_data"}

    response.headers["Cache-Control"] = "public, max-age=60, s-maxage=60"

    latest = {}
    if GLOBAL_CACHE["source_type"] == "Classic Website":
        latest = data[0]
    else:
        latest = data[-1]

    return {
        "status": "success",
        "source": GLOBAL_CACHE["source_type"],
        "bullion_buy": latest.get("bullion_buy"),
        "ornament_buy": latest.get("ornament_buy"),
        "updated_at": GLOBAL_CACHE["last_updated"]
    }

@app.get("/api/history")
def get_history(response: Response):
    response.headers["Cache-Control"] = "public, max-age=60, s-maxage=60"
    return {
        "count": len(GLOBAL_CACHE["gold_bar_data"]),
        "source": GLOBAL_CACHE["source_type"],
        "data": GLOBAL_CACHE["gold_bar_data"],
        "updated_at": GLOBAL_CACHE["last_updated"]
    }

@app.get("/api/percent_jewelry")
def get_percent(response: Response):
    response.headers["Cache-Control"] = "public, max-age=60, s-maxage=60"
    return {
        "count": len(GLOBAL_CACHE["jewelry_percent"]),
        "source": GLOBAL_CACHE["source_type"],
        "data": GLOBAL_CACHE["jewelry_percent"],
        "updated_at": GLOBAL_CACHE["last_updated"]
    }

@app.get("/api/shops")
def get_shops(response: Response):
    response.headers["Cache-Control"] = "public, max-age=60, s-maxage=60"
    return {
        "count": len(GLOBAL_CACHE["shop_data"]),
        "data": GLOBAL_CACHE["shop_data"],
        "updated_at": GLOBAL_CACHE["last_updated"]
    }

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)